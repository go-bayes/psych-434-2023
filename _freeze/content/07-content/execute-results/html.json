{
  "hash": "1cb5cf796dce7a5a31a2819ede36c07f",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Causal Inference: Definitions, Assumptions, Causal Graphs\"\ndate: \"2023-MAY-09\"\nexecute:\n  warning: false\n---\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Causal graph shows potential for selection bias from loss to follow up or non-response. To address this, we multiply impute missing values on the assumption that missing values are random conditional on the imputation model (MAR).](07-content_files/figure-html/fig-dag-1.png){#fig-dag width=80%}\n:::\n:::\n\n\n\n\n## Slides\n\n[PREVIEW](/slides/07-slides.html)\n\n<div>\n\n\n```{=html}\n<iframe class=\"slide-deck\" src=\"/slides/07-slides.html\"></iframe>\n```\n\n\n</div>\n\nOpen in browser [here](/slides/07-slides.html){target=\"_blank\"}\n\n\n\n\n## Excercises\n\n[PREVIEW](/slides/07-exercise.html)\n\n<div>\n\n\n```{=html}\n<iframe class=\"slide-deck\" src=\"/slides/07-exercise.html\"></iframe>\n```\n\n\n</div>\n\nOpen in browser [here](/slides/07-exercise.html){target=\"_blank\"}\n\n\n\n\n\n\n## Downloads\n\nBelow is a link to the R script that will allow you to download the data and exercises. Copy the contents on your screen to a new R script, and run the script from the begging. Before class, it will be useful for you to: \n\n1. Run \"source()\" file. \n2. Download the synthetic data. \n3. Create a folder in your Rstudio project called \"data\"\n4. Place the downloaded file in your data folder.\n\n\n[link to script for this week ](https://raw.githubusercontent.com/go-bayes/psych-434-2023/ab93ccac0b03c9ae46ab310f37d32951b77e406d/scripts/434-intro-causal-inference-week-7.R)\n\n\n\n\n## Overview\n  \n  \n\n\n## Introduction: Motivating Example\n\nConsider the following cross-cultural question: \n\n> Does bilingualism improve cognitive abilities in children? \n\nThere is evidence that bilingual children perform better oat cognitive tasks, but is learning more than one language a confounding factors? \n\nIn this lecture, we will discuss the fundamental problem of causal inference, its assumptions, and how we can address this issue in both experimental and observational settings.\n\n\n\n## Part 1: The Fundamental Problem of Causal Inference as a Missing Data Problem \n\nTo understand the fundamental problem of causal inference, let's first define two potential outcomes for each individual in our study:\n\n- $Y_i^{a = 1}$: The cognitive ability of child $i$ if they were bilingual.  This is the counterfactual outcome when A = 1.\n- $Y_i^{a = 0}$:: The cognitive ability of child $i$ if they were monolingual. This is the counterfactual outcome when A = 0.\n\nThe causal effect of bilingualism on cognitive ability for individual $i$ is then defined as the difference between these potential outcomes:\n\n$$\n\\text{Causal Effect}_i = Y^{a=1} - Y^{a=0} \n$$\n\nNote that sometimes we will write this contrast as:\n\n\n$$\n\\text{Causal Effect}_i = Y(1) - Y(0)\n$$\n\nor\n\n$$\n\\text{Causal Effect}_i = Y^{1} - Y^{0} \n$$\n\n\n\nWe say there is a causal effect if: \n\n$$\nY^{a=1} - Y^{a=0}  \\neq 0\n$$\n\n\n\n\nThe Philosopher David Hume defines causation in the following way: \n\n> “We may define a cause to be an object followed by another, and where all the objects, similar to the first, are followed by objects similar to the second [definition 1]. Or, in other words, where, if the first object had not been, the second never would have existed [definition 2].” \n- Enquiries Concerning Human Understanding, and Concerning the Principles of Morals\n\n\nThis is a contrast between two states of the world. One in which a child recieves bi-lingual exposure and one in which a child does not.\n\n\nHowever, consider that we can only observe one of the potential outcomes for each child.  The contrast we require for identifying a causal effect is typically not observed.\n\n\nRobert Frost writes, \n\n> Two roads diverged in a yellow wood,\u000b\nAnd sorry I could not travel both\u000b\nAnd be one traveler, long I stood\u000b\nAnd looked down one as far as I could\u000b\nTo where it bent in the undergrowth;\u000b\n\n>Then took the other, as just as fair,\u000b\nAnd having perhaps the better claim,\u000b\nBecause it was grassy and wanted wear;\u000b\nThough as for that the passing there\u000b\nHad worn them really about the same,\u000b\n\u000b\n>And both that morning equally lay\u000b\nIn leaves no step had trodden black.\u000b\nOh, I kept the first for another day!\u000b\nYet knowing how way leads on to way,\u000b\nI doubted if I should ever come back.\u000b\n\n> I shall be telling this with a sigh\u000b\nSomewhere ages and ages hence:\u000b\nTwo roads diverged in a wood, and I—\u000b\nI took the one less traveled by,\u000b\nAnd that has made all the difference. -- The Road Not Taken\n\n\n\n**“And sorry I could not travel both. And be one traveller$\\dots$”**  \n\nThe fact that causal contrasts are not observed on individuals is called \"The fundamental problem of causal inference.\"\n\n\nWe will discuss how this missing data problem arises in different research designs and explore strategies for addressing it.  \n\nFor now, note that the problem isn't merely one of statistical analysis on the data. **The problem is that the relevant data to identify individual causal effects are missing.**\n\n\n\n## Part 2: Fundamental Assumptions of Causal Inference \n\n\n\n\n\nAlthough we typically cannot observe individual causal effects, under certain assumptions we can obtain average causal effects.\n\n\n\\begin{align}\nE(\\delta) = E(Y^{a=1} - Y^{a=0})\\\\\n          ~  = E(Y^{a=1}) - E(Y^{a=0}) \\\\\n          ~  = ATE\n\\end{align} \n\n\n\n\n## Assumptions Required for Estimating Causal Effects From Data\n\n- Causal Consistency: The values of exposure under comparisons correspond to well-defined interventions that, in turn, correspond to the versions of treatment in the data.(see: Chatton, Hernan & Robbins)\n- Positivity:  The probability of receiving every value of the exposure within all strata of co-variates is greater than zero \n- Exchangeablility: The conditional probability of receiving every value of an exposure level, though not decided by the investigators, depends only on the measured covariates (see: Chatton, Hernan & Robbins)\n\n\n\n\n### Causal Consistency\n\n\n\nThe fundamental problem of causal inference is that an individual cannot receive two different exposures at the same time. For a binary exposure, an observed outcome under an exposure can be can be expressed: \n\n$$Y^{observed} = AY^{a=1} + (1-A)Y^{a=0}$$\n\nTable @tbl-consistency expresses the relationship between observable outcomes and counterfactual outcomes as a contingency table. \n\n\n\n\n::: {#tbl-consistency .cell warnings='false' tbl-cap='Causal Consistency'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Group </th>\n   <th style=\"text-align:left;\"> Exposure_A_1 </th>\n   <th style=\"text-align:left;\"> No_Exposure_A_0 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Y(1) </td>\n   <td style=\"text-align:left;\"> Observable </td>\n   <td style=\"text-align:left;\"> Counterfactual </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Y(0) </td>\n   <td style=\"text-align:left;\"> Counterfactual </td>\n   <td style=\"text-align:left;\"> Observable </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\\begin{table}\n\\begin{center}\n\\begin{tabular}{ |l|l|l| } \n \\hline\n Group & $Y^{a = 1}$ & $Y^{a=0}$ \\\\ \n \\hline\n Exposure $A = 1$ & Observable Y & Counterfactual \\\\ \n No Exposure  $A = 0$ & Counterfactual & Observable Y  \\\\ \n \\hline\n\\end{tabular}\n\\end{center}\n\\label{tab:consistency}\n\\end{table}\n\nWhen the counterfactual consistency theorem holds, and individuals observed outcome under an exposure is equal to their counterfactual outcome under that exposure: \n\n\n\n$$\nY_i = Y_i^1 ~\\text{if}~ A_i = 1\n$$\n\nand \n\n$$\nY_i = Y_i^0 ~\\text{if}~  A_i = 0\n$$\n\n\n\n\n\n\n           \n\n### Positivity\n\n\nThe probability of receiving every value of the exposure within all strata of co-variates is greater than zero \n\n\n\\begin{equation}\n0 < \\Pr(A=a|L)<1, ~ \\forall a \\in A, ~ \\forall a \\in L\n\\end{equation}\n\n\nThere are two types of positivity violations\n  - Random non-positivity:  the casual effect of aging with observations missing at ages 40-41 (we use parametric models as a work around.)\n  - Deterministic non-positivity: the causal effect of hysterectomy in biological males (assumption violated).\n\n\n\n\n\n### Conditional exchangeablity\n\nGiven the observed covariates, the treatment assignment is independent of the potential outcomes. Mathematically, this can be expressed as.\n\n\n\n\n$$Y^a\\coprod A \\text{ for all }a$$\n\n\nor with strata of confounding covarates:\n\n\n$$Y^a\\coprod  A \\text{ for all }a|L$$\n\n\nWhen conditional exchangability holds:\n\n\n$$\n\\begin{aligned}\nATE = E[Y^{a=1}|L = l] - E[Y^{a=0}|L = l] ~ \\text{for any value}~l\n\\end{aligned}\n$$\n\n\n> \"We say that a set L of measured non-descendants of L is a sufficient set for confounding adjustment when conditioning on L blocks all backdoor paths–that is, the treated and the untreated are exchangeable within levels of L\" (Hernan & Robins, What IF p. 86)\n\n\n\n### Positivity\n\nThere is a non-zero probability of receiving each treatment level for all strata of the observed covariates. This means that every individual has some chance of being in either treatment or control group.\n\n\n## Part 3: Causal Inference from Randomized Experiments\n\nRandomized experiments can help us overcome the the fundamental problem of causal inference. By randomly assigning individuals to treatment (bilingual) or control (monolingual) groups, we create comparable groups that allow us to estimate causal effects. \n\nRandom assignment ensures that all observed and unobserved confounders are balanced between the treatment and control groups on average, satisfying the conditionally exchangeable assumption.\n\nThe key benefits of randomized experiments are:\n\n1. Unbiased estimation of average treatment effects.\n2. Control of both observed and unobserved confounding.\n3. Facilitated interpretation of causal effects.\n\n\nNotice that the results of an experiment recover Average Treatment Effects, not individual causal effects.  Although a treament might be beneficial for the majority of people, it might not be benefitial for you.  \n\nThis consideration may be extended to subgroups.  Although a treatment might be beneficial, on average, for the majority of a population, it might not be benefitial for a sub-population.  However, unlike individual causal effects, we may obtain causal effect estimates within sub-populations.  We will will return to this topic next week.  \n\n\n\n\n## Part 4: Causal Graphs and Directed Acyclic Graphs (DAGs) \n\nCausal graphs, also known as directed acyclic graphs (DAGs), provide a powerful way to represent causal relationships between variables. In a DAG, nodes represent variables, and directed edges represent causal relationships between them.\n\nSee this week's lectures slides where we cover:\n\n\n1. DAG basics: How to construct and interpret DAGs, including the concepts of parents, children, ancestors, and descendants.\n2. D-separation and conditional independence: Understanding when variables are conditionally independent given a set of conditioning variables in a DAG, and how this relates to the concept of d-separation.\n3. Identifying confounders: Using DAGs to identify confounders that must be controlled for in order to estimate causal effects.\n4. Collider bias and conditioning: Understanding how conditioning on colliders can induce bias in causal estimates, and how to avoid this issue.\n5. Mediation and direct/indirect effects: if we are interested in total effects, we should not condition on a mediator.\n\n\n\n\n##  Clear Advice for Drawing Causal Graphs\n\n- Ensure that causes come before effects. Assign time indices to your variables.\n- Organize your variables chronologically.\n- Simplify your graph by removing unnecessary nodes that don't impact the assessment of bias between an exposure and an outcome.\n- Keep in mind that Directed Acyclic Graphs (DAGs) are qualitative tools. They don't represent non-linear associations or interactions. \n- Avoid depicting interactions by crossing arrows.\n- Remember that DAGs are distinct from graphs used in Structural Equation Modeling (SEM). Be cautious of SEM literature, as it often overlooks the assumptions needed for causal inference.\n\n\n## Summary: Drawing Causal Graphs (DAGs)\n\n- Directed Acyclic Graphs (DAGs) help visualize sources of bias.\n\n- There are five main sources of bias:\n  1. Temporal order ambiguity: Uncertainty about whether causes precede effects. Solution: Collect time series data or clarify assumptions when unavailable.\n  2. Common causes of exposure and outcome: Address this by including common causes in your statistical model (e.g., using regression).\n  3. Conditioning on a mediator: Avoid this unless mediation is of interest.\n  4. Conditioning on a collider: Refrain from doing this.\n  5. Bias induced by conditioning on a confounder's descendant: Draw your DAG and follow guidelines for points 1-4.\n\n- Important Note 1: In observational studies, it's impossible to guarantee complete control for confounding. Always conduct sensitivity analyses. Techniques for sensitivity analyses will be discussed next week.\n\n- Important Note 2: Methods for computing causal effects for group comparisons will be covered in the following week's lecture.\n\n\n## Conclusion\n\nIn this lecture, we discussed the fundamental problem of causal inference, its assumptions, the role of randomized experiments in estimating causal effects, the challenges in identifying causal effects from observational data, and the use of causal graphs to represent and analyze causal relationships. You have learned how to use causal graphs to identify sources of bias. In the weeks ahead, we will apply this knowledge to address questions in cross-cultural psychology.\n\n\n\n\n\n",
    "supporting": [
      "07-content_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}